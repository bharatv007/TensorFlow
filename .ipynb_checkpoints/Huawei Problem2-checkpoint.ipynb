{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharatv/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = trX.reshape(-1, 28, 28, 1)  # 28x28x1 input img\n",
    "teX = teX.reshape(-1, 28, 28, 1)  # 28x28x1 input img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X=tf.placeholder(tf.float32,[None,28,28,1])\n",
    "Y=tf.placeholder(tf.float32,[None,10])\n",
    "phase = tf.placeholder(tf.bool, name='phase')\n",
    "layers=1\n",
    "W1 = tf.get_variable(\"W1\",[3,3,1,16],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W2 = tf.get_variable(\"W2\",[3,3,16,32],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W3 = tf.get_variable(\"W3\",[3,3,32,64],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W=[W1,W2,W3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(X,w,s,phase):\n",
    "    l1=tf.nn.conv2d(X,w,strides=[1,s,s,1],padding=\"SAME\")\n",
    "    l2=tf.contrib.layers.batch_norm(l1,center=True, scale=True, is_training=phase)\n",
    "    l3=tf.nn.relu(l2)\n",
    "    l4=tf.nn.max_pool(l3,ksize=[1,s,s,1],strides=[1,s,s,1],padding='SAME')\n",
    "    return l4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,W,layers,phase):\n",
    "#     X_resized=tf.image.resize_images(X,[14,14])\n",
    "    X_resized=X\n",
    "    for l in range(layers):\n",
    "        print(W[l])\n",
    "        p=layer(X_resized,W[l],2,phase)\n",
    "        X_resized=p\n",
    "    FC1=tf.contrib.layers.flatten(p)\n",
    "    out=tf.contrib.layers.fully_connected(FC1,10,activation_fn=None)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'W1:0' shape=(3, 3, 1, 16) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "num_minibatches=int(trX.shape[0]/128)\n",
    "\n",
    "#Output from the model\n",
    "Y_hat=model(X,W,layers,phase)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y_hat,labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# Evaluate Model\n",
    "predict_op = tf.argmax(Y_hat, 1)\n",
    "correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "#Initializer\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation]\n",
    "    shuffled_Y = Y[permutation]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[(k+1)*mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[(k+1)*mini_batch_size:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.431020\n",
      "Cost after epoch 10: 0.055619\n",
      "Cost after epoch 20: 0.037081\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    seed=3\n",
    "    sess.run(init)\n",
    "    for i in range(0,100):\n",
    "        minibatch_cost = 0.\n",
    "        num_minibatches = int(trX.shape[0] / 128)\n",
    "        seed=seed+1\n",
    "        minibatches=random_mini_batches(trX,trY,128,seed)\n",
    "        for minibatch in minibatches:\n",
    "            minibatch_x,minibatch_y=minibatch\n",
    "            _,temp_cost=sess.run([optimizer,cost],feed_dict={X:minibatch_x,Y:minibatch_y,phase:True})\n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "        if i % 10 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (i, minibatch_cost))\n",
    "        # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(accuracy)\n",
    "    train_accuracy = accuracy.eval({X: trX, Y: trY,phase:False})\n",
    "    test_accuracy = accuracy.eval({X: teX, Y: teY,phase:False})\n",
    "    print(\"Train Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
